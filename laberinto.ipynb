{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '.VENV (Python 3.11.9)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"c:/USERS/JAVIER VALBUENA/DESKTOP/PY ML/.VENV/SCRIPTS/PYTHON.EXE\" -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ============================\n",
    "# CONFIGURACIÓN DEL LABERINTO\n",
    "# ============================\n",
    "\n",
    "def crear_laberinto(tamaño):\n",
    "    \"\"\"Crea un laberinto de tamaño NxN con obstáculos y una meta.\"\"\"\n",
    "    laberinto = np.zeros((tamaño, tamaño))\n",
    "    # Generar obstáculos aleatorios\n",
    "    for _ in range(int(tamaño * tamaño * 0.3)):  # 30% del laberinto son obstáculos\n",
    "        x, y = np.random.randint(0, tamaño, size=2)\n",
    "        laberinto[x, y] = 1\n",
    "    # Asegurar que el inicio y la meta estén libres\n",
    "    laberinto[0, 0] = 0  # Inicio\n",
    "    laberinto[tamaño-1, tamaño-1] = 2  # Meta\n",
    "    return laberinto\n",
    "\n",
    "laberinto = crear_laberinto(100)\n",
    "\n",
    "# Mostrar el laberinto inicial\n",
    "plt.imshow(laberinto, cmap=\"gray\")\n",
    "plt.title(\"Laberinto inicial\")\n",
    "plt.show()\n",
    "\n",
    "# ============================\n",
    "# PARÁMETROS Y FUNCIONES BÁSICAS\n",
    "# ============================\n",
    "\n",
    "# Definimos las acciones: arriba, abajo, izquierda, derecha\n",
    "acciones = [\"arriba\", \"abajo\", \"izquierda\", \"derecha\"]\n",
    "\n",
    "def es_movimiento_valido(laberinto, pos_actual, accion):\n",
    "    \"\"\"Valida si un movimiento es válido dado el laberinto.\"\"\"\n",
    "    x, y = pos_actual\n",
    "    if accion == \"arriba\" and x > 0 and laberinto[x-1, y] != 1:\n",
    "        return (x-1, y)\n",
    "    if accion == \"abajo\" and x < laberinto.shape[0]-1 and laberinto[x+1, y] != 1:\n",
    "        return (x+1, y)\n",
    "    if accion == \"izquierda\" and y > 0 and laberinto[x, y-1] != 1:\n",
    "        return (x, y-1)\n",
    "    if accion == \"derecha\" and y < laberinto.shape[1]-1 and laberinto[x, y+1] != 1:\n",
    "        return (x, y+1)\n",
    "    return pos_actual  # Si no es válido, mantener la posición\n",
    "\n",
    "\n",
    "\n",
    "# ============================\n",
    "# IMPLEMENTACIÓN DEL Q-LEARNING\n",
    "# ============================\n",
    "\n",
    "# Parámetros del modelo\n",
    "alpha = 0.1  # Tasa de aprendizaje\n",
    "gamma = 0.9  # Factor de descuento\n",
    "epsilon = 0.1  # Exploración-explotación\n",
    "episodios = 1000\n",
    "\n",
    "# Inicializamos la tabla Q\n",
    "q_table = np.zeros((*laberinto.shape, len(acciones)))\n",
    "\n",
    "# Entrenamiento del agente\n",
    "for episodio in range(episodios):\n",
    "    pos_actual = (0, 0)  # El agente siempre comienza en la posición inicial\n",
    "    while laberinto[pos_actual] != 2:  # Mientras no llegue a la meta\n",
    "        # Elegir acción: explorar o explotar\n",
    "        if np.random.random() < epsilon:  # Exploración\n",
    "            accion = np.random.choice(range(len(acciones)))\n",
    "        else:  # Explotación\n",
    "            accion = np.argmax(q_table[pos_actual])\n",
    "\n",
    "        # Determinar el siguiente estado\n",
    "        nueva_pos = es_movimiento_valido(laberinto, pos_actual, acciones[accion])\n",
    "        recompensa = 1 if laberinto[nueva_pos] == 2 else -0.01\n",
    "\n",
    "        # Actualizar la tabla Q\n",
    "        q_table[pos_actual + (accion,)] += alpha * (\n",
    "            recompensa + gamma * np.max(q_table[nueva_pos]) - q_table[pos_actual + (accion,)]\n",
    "        )\n",
    "\n",
    "        # Mover al siguiente estado\n",
    "        pos_actual = nueva_pos\n",
    "\n",
    "# ============================\n",
    "# EVALUACIÓN DEL MODELO\n",
    "# ============================\n",
    "\n",
    "def probar_modelo(laberinto, q_table):\n",
    "    \"\"\"Prueba el agente en el laberinto y devuelve el recorrido.\"\"\"\n",
    "    pos_actual = (0, 0)\n",
    "    recorrido = [pos_actual]\n",
    "    while laberinto[pos_actual] != 2:  # Mientras no llegue a la meta\n",
    "        accion = np.argmax(q_table[pos_actual])  # Elegir la mejor acción\n",
    "        pos_actual = es_movimiento_valido(laberinto, pos_actual, acciones[accion])\n",
    "        recorrido.append(pos_actual)\n",
    "    return recorrido\n",
    "\n",
    "# Generar el recorrido del agente\n",
    "recorrido = probar_modelo(laberinto, q_table)\n",
    "\n",
    "def mostrar_recorrido(laberinto, recorrido):\n",
    "    \"\"\"Muestra el recorrido del agente en el laberinto.\"\"\"\n",
    "    laberinto_con_camino = laberinto.copy()\n",
    "    for x, y in recorrido:\n",
    "        laberinto_con_camino[x, y] = 0.5  # Marcar el camino\n",
    "    plt.imshow(laberinto_con_camino, cmap=\"gray\")\n",
    "    plt.title(\"Recorrido del agente\")\n",
    "    plt.show()\n",
    "\n",
    "# Mostrar el recorrido\n",
    "mostrar_recorrido(laberinto, recorrido)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".VENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
